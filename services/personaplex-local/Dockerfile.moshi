# Moshi Voice Server - GPU-Accelerated STT/TTS for PersonaPlex
# Created: February 13, 2026
# 
# This Dockerfile builds a GPU-enabled Moshi server for full PersonaPlex voice:
# - Moshi STT + TTS with female voice (moshika-pytorch-bf16 / NATF2)
# - GPU-accelerated on RTX 5090 (32GB VRAM, CUDA 12.0)
# - Runtime model download from Hugging Face cache
# - PersonaPlex Bridge runs on Windows host, connects to this container
#
# Build: docker build -t mycosoft/moshi-voice:latest -f Dockerfile.moshi .
# Run:   docker run -d --name moshi-voice --gpus all -p 8998:8998 mycosoft/moshi-voice:latest

FROM nvidia/cuda:12.8.0-runtime-ubuntu22.04

# Prevent interactive prompts
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-dev \
    python3-pip \
    git \
    wget \
    curl \
    libsndfile1 \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.11 as default
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1

# Upgrade pip
RUN python3 -m pip install --upgrade pip setuptools wheel

# Set working directory
WORKDIR /app

# Install PyTorch nightly with CUDA 12.8 support (required for RTX 5090 sm_120 Blackwell)
RUN pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128

# Install Moshi and dependencies
RUN pip install \
    moshi \
    sphn \
    sentencepiece \
    encodec \
    huggingface-hub \
    websockets \
    aiohttp

# Model downloads on first run and is cached in the container volume

# Environment variables
ENV MOSHI_HOST=0.0.0.0
ENV MOSHI_PORT=8998
ENV CUDA_VISIBLE_DEVICES=0
ENV TORCH_HOME=/root/.cache/torch
ENV MOSHI_DEVICE=cuda

# Expose Moshi port
EXPOSE 8998

# Health check (WebSocket endpoint, expecting upgrade message)
HEALTHCHECK --interval=30s --timeout=10s --start-period=90s --retries=3 \
    CMD curl -f http://localhost:8998/ 2>&1 | grep -q "websocket" || exit 1

# Create startup script
RUN echo '#!/bin/bash\n\
set -e\n\
echo "========================================"\n\
echo "Moshi Voice Server - Full PersonaPlex"\n\
echo "Female Voice: NATF2 (Moshika)"\n\
echo "========================================"\n\
echo ""\n\
echo "GPU Check:"\n\
python3 -c "import torch; print(f\"  PyTorch: {torch.__version__}\")"\n\
python3 -c "import torch; print(f\"  CUDA available: {torch.cuda.is_available()}\")"\n\
python3 -c "import torch; print(f\"  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else None}\")"\n\
python3 -c "import torch; print(f\"  VRAM: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\" if torch.cuda.is_available() else \"\")" 2>/dev/null || true\n\
echo ""\n\
echo "Starting Moshi server..."\n\
echo "  Model: kyutai/moshika-pytorch-bf16"\n\
echo "  Port: $MOSHI_PORT"\n\
echo "  Host: $MOSHI_HOST"\n\
echo "  Device: $MOSHI_DEVICE"\n\
echo ""\n\
echo "Model will load and warm up (60-90 seconds)..."\n\
echo ""\n\
exec python3 -m moshi.server --host $MOSHI_HOST --port $MOSHI_PORT --hf-repo kyutai/moshika-pytorch-bf16 --device $MOSHI_DEVICE\n\
' > /app/start-moshi.sh && chmod +x /app/start-moshi.sh

# Run Moshi server
CMD ["/app/start-moshi.sh"]
