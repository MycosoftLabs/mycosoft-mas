# Moshi Voice Server - RTX 5090 Full GPU (Blackwell sm_120)
# Updated: February 17, 2026
#
# VERIFIED base image + PyTorch nightly cu124 which supports sm_120 via JIT.
# Model cached in Docker volume "moshi-model-cache" - never re-downloaded.
#
# Build (~15-20 min first time, ~2 min with layer cache):
#   docker build -t mycosoft/moshi-voice:latest -f Dockerfile.moshi .
#
# Run:
#   docker run -d --name moshi-voice --gpus all --restart unless-stopped \
#     -p 8998:8998 -v moshi-model-cache:/root/.cache \
#     -e MOSHI_DEVICE=cuda mycosoft/moshi-voice:latest

# nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04 verified tag (pre-pulled Feb 17 2026)
FROM nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.11 python3.11-dev python3-pip \
    git wget curl libsndfile1 ffmpeg \
    && rm -rf /var/lib/apt/lists/*

RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 && \
    update-alternatives --install /usr/bin/python  python  /usr/bin/python3.11 1 && \
    python3 -m pip install --upgrade pip setuptools wheel

WORKDIR /app

# PyTorch nightly cu124 - supports RTX 5090 sm_120 Blackwell via PTX JIT
# cu124 nightly index is well-established and has Linux amd64 wheels
RUN pip install --pre torch torchaudio \
        --index-url https://download.pytorch.org/whl/nightly/cu124 \
        --no-deps && \
    pip install --pre torchvision \
        --index-url https://download.pytorch.org/whl/nightly/cu124 \
        --no-deps 2>/dev/null || true

# Install remaining Python deps
RUN pip install numpy

# Moshi and audio stack
RUN pip install \
    moshi \
    sphn \
    sentencepiece \
    huggingface-hub \
    websockets \
    aiohttp

# Env - model cache in volume (persists across rebuilds, never re-downloads)
ENV MOSHI_HOST=0.0.0.0 \
    MOSHI_PORT=8998 \
    CUDA_VISIBLE_DEVICES=0 \
    MOSHI_DEVICE=cuda \
    HF_HOME=/root/.cache/huggingface \
    TORCH_HOME=/root/.cache/torch \
    TORCHDYNAMO_DISABLE=1 \
    TOKENIZERS_PARALLELISM=false

EXPOSE 8998

# Startup: GPU check then launch Moshi
RUN printf '#!/bin/bash\nset -e\n\
echo "=== Moshi Voice - RTX 5090 GPU ==="\n\
python3 -c "import torch; v=torch.__version__; ok=torch.cuda.is_available(); \
n=torch.cuda.get_device_name(0) if ok else None; \
m=round(torch.cuda.get_device_properties(0).total_memory/1073741824,1) if ok else 0; \
print(f\"  PyTorch {v}  CUDA={ok}  GPU={n}  VRAM={m}GB\")"\n\
echo "  Model cache: $HF_HOME"\n\
echo "  Device: $MOSHI_DEVICE  Port: $MOSHI_PORT"\n\
echo "  Loading model (60-90s first GPU run)..."\n\
exec python3 -m moshi.server \\\n\
    --host "$MOSHI_HOST" --port "$MOSHI_PORT" \\\n\
    --hf-repo kyutai/moshika-pytorch-bf16 \\\n\
    --device "$MOSHI_DEVICE"\n\
' > /app/start-moshi.sh && chmod +x /app/start-moshi.sh

CMD ["/app/start-moshi.sh"]
