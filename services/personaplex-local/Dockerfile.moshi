# Moshi Voice Server - RTX 5090 GPU (Blackwell sm_120)
# Updated: February 17, 2026
#
# Full GPU inference - CUDA 12.8 + PyTorch nightly cu128 for sm_120 Blackwell.
# Model cache mounted via Docker volume so it never re-downloads.
#
# Build:
#   docker build -t mycosoft/moshi-voice:latest -f Dockerfile.moshi .
#
# Run (first time - downloads model ~7GB to volume):
#   docker run -d --name moshi-voice --gpus all --restart unless-stopped \
#     -p 8998:8998 \
#     -v moshi-model-cache:/root/.cache \
#     mycosoft/moshi-voice:latest
#
# Run (subsequent - model already in volume, starts in ~60s):
#   Same command above - cache is persistent.

# CUDA 12.8 devel image includes cuDNN, NCCL, and full toolkit for sm_120 Blackwell
FROM nvidia/cuda:12.8.0-cudnn-devel-ubuntu22.04

# Prevent interactive prompts
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.11 \
    python3.11-dev \
    python3-pip \
    git \
    wget \
    curl \
    libsndfile1 \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.11 as default
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 && \
    update-alternatives --install /usr/bin/python  python  /usr/bin/python3.11 1

# Upgrade pip
RUN python3 -m pip install --upgrade pip setuptools wheel

WORKDIR /app

# PyTorch nightly with CUDA 12.8 - supports sm_120 (RTX 5090 Blackwell)
RUN pip install --pre torch torchvision torchaudio \
        --index-url https://download.pytorch.org/whl/nightly/cu128 \
    && python3 -c "import torch; assert torch.cuda.is_available(), 'CUDA must be available at build time is not required - runtime check will confirm'"

# Moshi and audio dependencies
RUN pip install \
    moshi \
    sphn \
    sentencepiece \
    huggingface-hub \
    websockets \
    aiohttp

# GPU env - model cache goes to volume /root/.cache so it persists across rebuilds
ENV MOSHI_HOST=0.0.0.0
ENV MOSHI_PORT=8998
ENV CUDA_VISIBLE_DEVICES=0
ENV MOSHI_DEVICE=cuda
ENV HF_HOME=/root/.cache/huggingface
ENV TORCH_HOME=/root/.cache/torch

# TORCHDYNAMO_DISABLE=1 avoids a second sm_120 compile-check warning
ENV TORCHDYNAMO_DISABLE=1

EXPOSE 8998

# Startup script - validates GPU then launches Moshi
RUN printf '#!/bin/bash\n\
set -e\n\
echo "========================================"\n\
echo "Moshi Voice Server - RTX 5090 GPU"\n\
echo "CUDA 12.8 / PyTorch cu128 / sm_120"\n\
echo "Female Voice: NATF2 (Moshika)"\n\
echo "========================================"\n\
echo ""\n\
echo "GPU Check:"\n\
python3 -c "import torch; v=torch.__version__; print(f\"  PyTorch : {v}\")"\n\
python3 -c "import torch; ok=torch.cuda.is_available(); print(f\"  CUDA    : {ok}\"); assert ok, \"CUDA not available\""\n\
python3 -c "import torch; n=torch.cuda.get_device_name(0); print(f\"  GPU     : {n}\")"\n\
python3 -c "import torch; p=torch.cuda.get_device_properties(0); print(f\"  VRAM    : {p.total_memory/(1024**3):.1f} GB  sm_{p.major}{p.minor}\")"\n\
echo ""\n\
echo "Model cache : $HF_HOME"\n\
echo "Server      : $MOSHI_HOST:$MOSHI_PORT"\n\
echo "Device      : $MOSHI_DEVICE"\n\
echo ""\n\
echo "Starting Moshi (model loads in 60-90s on first GPU run)..."\n\
exec python3 -m moshi.server \\\n\
    --host  "$MOSHI_HOST" \\\n\
    --port  "$MOSHI_PORT" \\\n\
    --hf-repo kyutai/moshika-pytorch-bf16 \\\n\
    --device "$MOSHI_DEVICE"\n\
' > /app/start-moshi.sh && chmod +x /app/start-moshi.sh

CMD ["/app/start-moshi.sh"]
